"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
self["webpackHotUpdate_N_E"]("app/page",{

/***/ "(app-pages-browser)/./components/model/constants.ts":
/*!***************************************!*\
  !*** ./components/model/constants.ts ***!
  \***************************************/
/***/ (function(module, __webpack_exports__, __webpack_require__) {

eval(__webpack_require__.ts("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LAYER_COLORS: function() { return /* binding */ LAYER_COLORS; },\n/* harmony export */   LAYER_EXPLANATIONS: function() { return /* binding */ LAYER_EXPLANATIONS; },\n/* harmony export */   LAYER_STATS: function() { return /* binding */ LAYER_STATS; }\n/* harmony export */ });\n/* __next_internal_client_entry_do_not_use__ LAYER_COLORS,LAYER_STATS,LAYER_EXPLANATIONS auto */ // Layer color definitions\nconst LAYER_COLORS = {\n    input: \"#60a5fa\",\n    cnn: \"#3b82f6\",\n    transformer: \"#9333ea\",\n    rnn: \"#22c55e\",\n    output: \"#f43f5e\",\n    mlp: \"#8b5cf6\",\n    graph: \"#06b6d4\",\n    residual: \"#f59e0b\",\n    normalization: \"#10b981\",\n    attention: \"#ec4899\",\n    pooling: \"#0ea5e9\",\n    dropout: \"#6366f1\",\n    embedding: \"#d946ef\",\n    flatten: \"#14b8a6\"\n};\n// Layer statistics\nconst LAYER_STATS = {\n    input: {\n        neurons: 150528,\n        inferenceTime: 0.1,\n        memoryUsage: 0.6,\n        activations: \"None\"\n    },\n    cnn: {\n        neurons: 32768,\n        inferenceTime: 1.5,\n        memoryUsage: 2.0,\n        filters: \"64→128→256\",\n        activations: \"ReLU\"\n    },\n    transformer: {\n        neurons: 49152,\n        inferenceTime: 4.2,\n        memoryUsage: 12.0,\n        heads: 8,\n        activations: \"GELU\"\n    },\n    rnn: {\n        neurons: 8192,\n        inferenceTime: 2.0,\n        memoryUsage: 3.2,\n        hiddenUnits: 512,\n        activations: \"Tanh\"\n    },\n    output: {\n        neurons: 1000,\n        inferenceTime: 0.2,\n        memoryUsage: 0.4,\n        activations: \"Softmax\"\n    },\n    mlp: {\n        neurons: 2048,\n        inferenceTime: 0.8,\n        memoryUsage: 1.6,\n        activations: \"ReLU\",\n        layers: \"2048→1024→512\" // More typical progression\n    },\n    graph: {\n        neurons: 1024,\n        inferenceTime: 1.8,\n        memoryUsage: 2.4,\n        activations: \"ReLU\",\n        aggregation: \"Mean\"\n    },\n    residual: {\n        neurons: 4096,\n        inferenceTime: 1.2,\n        memoryUsage: 2.4,\n        activations: \"ReLU\",\n        connections: \"Skip\"\n    },\n    normalization: {\n        neurons: 512,\n        inferenceTime: 0.2,\n        memoryUsage: 0.4,\n        type: \"BatchNorm\",\n        momentum: 0.99\n    },\n    attention: {\n        neurons: 3072,\n        inferenceTime: 1.8,\n        memoryUsage: 4.8,\n        heads: 8,\n        activations: \"Softmax\"\n    }\n};\n// Layer explanations\nconst LAYER_EXPLANATIONS = {\n    input: {\n        title: \"Input Layer\",\n        description: \"This layer processes raw input data (224\\xd7224 RGB images) and prepares it for the neural network. It applies normalization to scale pixel values between -1 and 1, making the data more suitable for deep learning.\",\n        technical: [\n            \"Input Shape: 224\\xd7224\\xd73\",\n            \"Normalization: [-1, 1]\",\n            \"Data Augmentation: Random crop, flip, rotation\"\n        ]\n    },\n    cnn: {\n        title: \"Convolutional Neural Network\",\n        description: \"The CNN block consists of 3 convolutional layers that progressively extract visual features. Each layer increases the number of filters while reducing spatial dimensions, allowing the network to learn hierarchical representations.\",\n        technical: [\n            \"3 Conv Layers: 64→128→256 filters\",\n            \"Kernel Size: 3\\xd73, Stride: 2\",\n            \"BatchNorm + ReLU activation\"\n        ]\n    },\n    transformer: {\n        title: \"Transformer Block\",\n        description: \"This block uses self-attention mechanisms to capture global relationships in the feature space. The multi-head attention allows the model to focus on different aspects of the input simultaneously.\",\n        technical: [\n            \"6 Attention Heads\",\n            \"Hidden Dim: 512\",\n            \"MLP Ratio: 4\",\n            \"LayerNorm + GELU\"\n        ]\n    },\n    rnn: {\n        title: \"Recurrent Neural Network\",\n        description: \"The RNN block processes sequential features using bidirectional LSTM cells. This allows the model to capture temporal dependencies in both forward and backward directions.\",\n        technical: [\n            \"Bidirectional LSTM\",\n            \"256 Hidden Units\",\n            \"Dropout: 0.2\",\n            \"Skip Connections\"\n        ]\n    },\n    output: {\n        title: \"Output Layer\",\n        description: \"The final layer produces class probabilities for 1000 different categories. It uses softmax activation to ensure all probabilities sum to 1, with temperature scaling for better calibration.\",\n        technical: [\n            \"1000 Output Classes\",\n            \"Softmax Activation\",\n            \"Temperature: 0.7\",\n            \"Cross-Entropy Loss\"\n        ]\n    },\n    mlp: {\n        title: \"Multi-Layer Perceptron\",\n        description: \"A fully connected neural network that transforms features through multiple dense layers. Each layer applies a linear transformation followed by non-linear activation.\",\n        technical: [\n            \"3 Dense Layers: 4096→2048→1024\",\n            \"ReLU Activation\",\n            \"Dropout: 0.5\",\n            \"Xavier Initialization\"\n        ]\n    },\n    graph: {\n        title: \"Graph Neural Network\",\n        description: \"Processes data structured as graphs, where each node aggregates information from its neighbors. Useful for molecular structures, social networks, and other graph-based data.\",\n        technical: [\n            \"Mean Aggregation\",\n            \"Edge Features\",\n            \"2-hop Neighborhood\",\n            \"Graph Attention\"\n        ]\n    },\n    residual: {\n        title: \"Residual Block\",\n        description: \"Implements skip connections that allow information to bypass layers directly. This helps mitigate the vanishing gradient problem and enables training of very deep networks.\",\n        technical: [\n            \"Identity Mapping\",\n            \"2 Conv Layers\",\n            \"Pre-activation\",\n            \"1\\xd71 Bottleneck\"\n        ]\n    },\n    normalization: {\n        title: \"Normalization Layer\",\n        description: \"Stabilizes training by normalizing feature distributions. Adapts to the statistics of each mini-batch while maintaining a running average for inference.\",\n        technical: [\n            \"Batch Normalization\",\n            \"Momentum: 0.99\",\n            \"Epsilon: 1e-5\",\n            \"Affine Transform\"\n        ]\n    },\n    attention: {\n        title: \"Attention Block\",\n        description: \"Computes dynamic weights for feature relationships. Each attention head specializes in different aspects of the input, enabling the model to capture complex dependencies.\",\n        technical: [\n            \"4 Attention Heads\",\n            \"Scaled Dot-Product\",\n            \"Key/Query Dim: 64\",\n            \"Softmax Temperature: 1.0\"\n        ]\n    }\n};\n\n\n;\n    // Wrapped in an IIFE to avoid polluting the global scope\n    ;\n    (function () {\n        var _a, _b;\n        // Legacy CSS implementations will `eval` browser code in a Node.js context\n        // to extract CSS. For backwards compatibility, we need to check we're in a\n        // browser context before continuing.\n        if (typeof self !== 'undefined' &&\n            // AMP / No-JS mode does not inject these helpers:\n            '$RefreshHelpers$' in self) {\n            // @ts-ignore __webpack_module__ is global\n            var currentExports = module.exports;\n            // @ts-ignore __webpack_module__ is global\n            var prevExports = (_b = (_a = module.hot.data) === null || _a === void 0 ? void 0 : _a.prevExports) !== null && _b !== void 0 ? _b : null;\n            // This cannot happen in MainTemplate because the exports mismatch between\n            // templating and execution.\n            self.$RefreshHelpers$.registerExportsForReactRefresh(currentExports, module.id);\n            // A module can be accepted automatically based on its exports, e.g. when\n            // it is a Refresh Boundary.\n            if (self.$RefreshHelpers$.isReactRefreshBoundary(currentExports)) {\n                // Save the previous exports on update so we can compare the boundary\n                // signatures.\n                module.hot.dispose(function (data) {\n                    data.prevExports = currentExports;\n                });\n                // Unconditionally accept an update to this module, we'll check if it's\n                // still a Refresh Boundary later.\n                // @ts-ignore importMeta is replaced in the loader\n                module.hot.accept();\n                // This field is set when the previous version of this module was a\n                // Refresh Boundary, letting us know we need to check for invalidation or\n                // enqueue an update.\n                if (prevExports !== null) {\n                    // A boundary can become ineligible if its exports are incompatible\n                    // with the previous exports.\n                    //\n                    // For example, if you add/remove/change exports, we'll want to\n                    // re-execute the importing modules, and force those components to\n                    // re-render. Similarly, if you convert a class component to a\n                    // function, we want to invalidate the boundary.\n                    if (self.$RefreshHelpers$.shouldInvalidateReactRefreshBoundary(prevExports, currentExports)) {\n                        module.hot.invalidate();\n                    }\n                    else {\n                        self.$RefreshHelpers$.scheduleUpdate();\n                    }\n                }\n            }\n            else {\n                // Since we just executed the code for the module, it's possible that the\n                // new exports made it ineligible for being a boundary.\n                // We only care about the case when we were _previously_ a boundary,\n                // because we already accepted this update (accidental side effect).\n                var isNoLongerABoundary = prevExports !== null;\n                if (isNoLongerABoundary) {\n                    module.hot.invalidate();\n                }\n            }\n        }\n    })();\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"file":"(app-pages-browser)/./components/model/constants.ts","mappings":";;;;;;iGAEA,0BAA0B;AACnB,MAAMA,eAAe;IAC1BC,OAAO;IACPC,KAAK;IACLC,aAAa;IACbC,KAAK;IACLC,QAAQ;IACRC,KAAK;IACLC,OAAO;IACPC,UAAU;IACVC,eAAe;IACfC,WAAW;IACXC,SAAS;IACTC,SAAS;IACTC,WAAW;IACXC,SAAS;AACX,EAAE;AAEF,mBAAmB;AACZ,MAAMC,cAAc;IACzBd,OAAO;QACLe,SAAS;QACTC,eAAe;QACfC,aAAa;QACbC,aAAa;IACf;IACAjB,KAAK;QACHc,SAAS;QACTC,eAAe;QACfC,aAAa;QACbE,SAAS;QACTD,aAAa;IACf;IACAhB,aAAa;QACXa,SAAS;QACTC,eAAe;QACfC,aAAa;QACbG,OAAO;QACPF,aAAa;IACf;IACAf,KAAK;QACHY,SAAS;QACTC,eAAe;QACfC,aAAa;QACbI,aAAa;QACbH,aAAa;IACf;IACAd,QAAQ;QACNW,SAAS;QACTC,eAAe;QACfC,aAAa;QACbC,aAAa;IACf;IACAb,KAAK;QACHU,SAAS;QACTC,eAAe;QACfC,aAAa;QACbC,aAAa;QACbI,QAAQ,gBAAgB,2BAA2B;IACrD;IACAhB,OAAO;QACLS,SAAS;QACTC,eAAe;QACfC,aAAa;QACbC,aAAa;QACbK,aAAa;IACf;IACAhB,UAAU;QACRQ,SAAS;QACTC,eAAe;QACfC,aAAa;QACbC,aAAa;QACbM,aAAa;IACf;IACAhB,eAAe;QACbO,SAAS;QACTC,eAAe;QACfC,aAAa;QACbQ,MAAM;QACNC,UAAU;IACZ;IACAjB,WAAW;QACTM,SAAS;QACTC,eAAe;QACfC,aAAa;QACbG,OAAO;QACPF,aAAa;IACf;AACF,EAAE;AAEF,qBAAqB;AACd,MAAMS,qBAAqB;IAChC3B,OAAO;QACL4B,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;SACD;IACH;IACA7B,KAAK;QACH2B,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;SACD;IACH;IACA5B,aAAa;QACX0B,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACA3B,KAAK;QACHyB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACA1B,QAAQ;QACNwB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACAzB,KAAK;QACHuB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACAxB,OAAO;QACLsB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACAvB,UAAU;QACRqB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACAtB,eAAe;QACboB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACArB,WAAW;QACTmB,OAAO;QACPC,aAAa;QACbC,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;AACF,EAAE","sources":["webpack://_N_E/./components/model/constants.ts?61c5"],"sourcesContent":["\"use client\";\n\n// Layer color definitions\nexport const LAYER_COLORS = {\n  input: '#60a5fa',\n  cnn: '#3b82f6',\n  transformer: '#9333ea',\n  rnn: '#22c55e',\n  output: '#f43f5e',\n  mlp: '#8b5cf6',\n  graph: '#06b6d4',\n  residual: '#f59e0b',\n  normalization: '#10b981',\n  attention: '#ec4899',\n  pooling: '#0ea5e9',\n  dropout: '#6366f1',\n  embedding: '#d946ef',\n  flatten: '#14b8a6'\n};\n\n// Layer statistics\nexport const LAYER_STATS = {\n  input: {\n    neurons: 150528, // 224 * 224 * 3 (standard ImageNet input)\n    inferenceTime: 0.1, // Input preprocessing is relatively fast\n    memoryUsage: 0.6, // ~0.6MB for float32 values\n    activations: 'None',\n  },\n  cnn: {\n    neurons: 32768, // More realistic for early conv layers\n    inferenceTime: 1.5,\n    memoryUsage: 2.0,\n    filters: '64→128→256', // Standard progression\n    activations: 'ReLU',\n  },\n  transformer: {\n    neurons: 49152, // 384 * 128 (sequence length * embedding dim)\n    inferenceTime: 4.2,\n    memoryUsage: 12.0, // Higher due to attention matrices\n    heads: 8, // Common in BERT-base like models\n    activations: 'GELU',\n  },\n  rnn: {\n    neurons: 8192, // 512 units * 16 timesteps\n    inferenceTime: 2.0,\n    memoryUsage: 3.2,\n    hiddenUnits: 512,\n    activations: 'Tanh',\n  },\n  output: {\n    neurons: 1000, // Standard ImageNet classes\n    inferenceTime: 0.2,\n    memoryUsage: 0.4,\n    activations: 'Softmax',\n  },\n  mlp: {\n    neurons: 2048,\n    inferenceTime: 0.8,\n    memoryUsage: 1.6,\n    activations: 'ReLU',\n    layers: '2048→1024→512' // More typical progression\n  },\n  graph: {\n    neurons: 1024,\n    inferenceTime: 1.8,\n    memoryUsage: 2.4,\n    activations: 'ReLU',\n    aggregation: 'Mean'\n  },\n  residual: {\n    neurons: 4096,\n    inferenceTime: 1.2,\n    memoryUsage: 2.4,\n    activations: 'ReLU',\n    connections: 'Skip'\n  },\n  normalization: {\n    neurons: 512,\n    inferenceTime: 0.2,\n    memoryUsage: 0.4,\n    type: 'BatchNorm',\n    momentum: 0.99\n  },\n  attention: {\n    neurons: 3072, // 384 * 8 heads\n    inferenceTime: 1.8,\n    memoryUsage: 4.8,\n    heads: 8,\n    activations: 'Softmax'\n  }\n};\n\n// Layer explanations\nexport const LAYER_EXPLANATIONS = {\n  input: {\n    title: \"Input Layer\",\n    description: \"This layer processes raw input data (224×224 RGB images) and prepares it for the neural network. It applies normalization to scale pixel values between -1 and 1, making the data more suitable for deep learning.\",\n    technical: [\n      \"Input Shape: 224×224×3\",\n      \"Normalization: [-1, 1]\",\n      \"Data Augmentation: Random crop, flip, rotation\"\n    ]\n  },\n  cnn: {\n    title: \"Convolutional Neural Network\",\n    description: \"The CNN block consists of 3 convolutional layers that progressively extract visual features. Each layer increases the number of filters while reducing spatial dimensions, allowing the network to learn hierarchical representations.\",\n    technical: [\n      \"3 Conv Layers: 64→128→256 filters\",\n      \"Kernel Size: 3×3, Stride: 2\",\n      \"BatchNorm + ReLU activation\"\n    ]\n  },\n  transformer: {\n    title: \"Transformer Block\",\n    description: \"This block uses self-attention mechanisms to capture global relationships in the feature space. The multi-head attention allows the model to focus on different aspects of the input simultaneously.\",\n    technical: [\n      \"6 Attention Heads\",\n      \"Hidden Dim: 512\",\n      \"MLP Ratio: 4\",\n      \"LayerNorm + GELU\"\n    ]\n  },\n  rnn: {\n    title: \"Recurrent Neural Network\",\n    description: \"The RNN block processes sequential features using bidirectional LSTM cells. This allows the model to capture temporal dependencies in both forward and backward directions.\",\n    technical: [\n      \"Bidirectional LSTM\",\n      \"256 Hidden Units\",\n      \"Dropout: 0.2\",\n      \"Skip Connections\"\n    ]\n  },\n  output: {\n    title: \"Output Layer\",\n    description: \"The final layer produces class probabilities for 1000 different categories. It uses softmax activation to ensure all probabilities sum to 1, with temperature scaling for better calibration.\",\n    technical: [\n      \"1000 Output Classes\",\n      \"Softmax Activation\",\n      \"Temperature: 0.7\",\n      \"Cross-Entropy Loss\"\n    ]\n  },\n  mlp: {\n    title: \"Multi-Layer Perceptron\",\n    description: \"A fully connected neural network that transforms features through multiple dense layers. Each layer applies a linear transformation followed by non-linear activation.\",\n    technical: [\n      \"3 Dense Layers: 4096→2048→1024\",\n      \"ReLU Activation\",\n      \"Dropout: 0.5\",\n      \"Xavier Initialization\"\n    ]\n  },\n  graph: {\n    title: \"Graph Neural Network\",\n    description: \"Processes data structured as graphs, where each node aggregates information from its neighbors. Useful for molecular structures, social networks, and other graph-based data.\",\n    technical: [\n      \"Mean Aggregation\",\n      \"Edge Features\",\n      \"2-hop Neighborhood\",\n      \"Graph Attention\"\n    ]\n  },\n  residual: {\n    title: \"Residual Block\",\n    description: \"Implements skip connections that allow information to bypass layers directly. This helps mitigate the vanishing gradient problem and enables training of very deep networks.\",\n    technical: [\n      \"Identity Mapping\",\n      \"2 Conv Layers\",\n      \"Pre-activation\",\n      \"1×1 Bottleneck\"\n    ]\n  },\n  normalization: {\n    title: \"Normalization Layer\",\n    description: \"Stabilizes training by normalizing feature distributions. Adapts to the statistics of each mini-batch while maintaining a running average for inference.\",\n    technical: [\n      \"Batch Normalization\",\n      \"Momentum: 0.99\",\n      \"Epsilon: 1e-5\",\n      \"Affine Transform\"\n    ]\n  },\n  attention: {\n    title: \"Attention Block\",\n    description: \"Computes dynamic weights for feature relationships. Each attention head specializes in different aspects of the input, enabling the model to capture complex dependencies.\",\n    technical: [\n      \"4 Attention Heads\",\n      \"Scaled Dot-Product\",\n      \"Key/Query Dim: 64\",\n      \"Softmax Temperature: 1.0\"\n    ]\n  }\n};"],"names":["LAYER_COLORS","input","cnn","transformer","rnn","output","mlp","graph","residual","normalization","attention","pooling","dropout","embedding","flatten","LAYER_STATS","neurons","inferenceTime","memoryUsage","activations","filters","heads","hiddenUnits","layers","aggregation","connections","type","momentum","LAYER_EXPLANATIONS","title","description","technical"],"sourceRoot":""}\n//# sourceURL=webpack-internal:///(app-pages-browser)/./components/model/constants.ts\n"));

/***/ })

});